{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5d13a-652d-439c-980e-8d6b673207c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json\n",
    "import random\n",
    "from sklearn.datasets import load_diabetes, load_digits, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "diabetes = load_diabetes()\n",
    "digits = load_diabetes()\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab565e5-97d3-41df-8726-16efc030fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class bayes_optimization_example:\n",
    "    def __init__(self, gbr_batch_size, n_processors, model):\n",
    "        self.n_procs = n_processors\n",
    "        self.gbr_batch_size = gbr_batch_size # how many points to evaluate when optimizing gaussian process\n",
    "        self.model = model\n",
    "\n",
    "    def metric(self, x, y):\n",
    "        if self.target_type == 'regression':\n",
    "            if x < y:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            if x > y:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def initialize(self, toy_data, hp_types, hp_ranges):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(toy_data.data, toy_data.target, test_size=0.5, random_state=42)\n",
    "        self.data = toy_data.data\n",
    "        self.target = toy_data.target\n",
    "        self.hp_types = hp_types\n",
    "        self.historical_scores = []\n",
    "        self.historical_points = []\n",
    "        self.hp_ranges = hp_ranges\n",
    "        for a in range(10):\n",
    "            r = [random.uniform(hp_ranges[x][0], hp_ranges[x][1]) \n",
    "                 if hp_types[x] == 'float' else random.randint(hp_ranges[x][0], hp_ranges[x][1]) \n",
    "                 for x in range(len(hp_ranges))]\n",
    "            if self.model == 'ElasticNet':\n",
    "                self.target_type = 'regression'\n",
    "                regr = ElasticNet(alpha = r[0], l1_ratio=r[1])\n",
    "            elif self.model == 'SVR':\n",
    "                self.target_type = 'regression'\n",
    "                regr = make_pipeline(StandardScaler(), SVR(C=r[0], epsilon=r[1]))\n",
    "            elif self.model == 'XGBoost':\n",
    "                self.target_type = 'classification'\n",
    "                regr = XGBClassifier(gamma=r[0], reg_lambda=r[1], colsample_bytree=r[2], \n",
    "                                     max_depth=r[3], min_child_weight=r[4], learning_rate=r[5])\n",
    "            regr.fit(self.X_train, self.y_train)\n",
    "            if self.target_type == 'regression':\n",
    "                self.historical_scores.append(str(r2_score(self.y_test, regr.predict(self.X_test))))\n",
    "            else:\n",
    "                self.historical_scores.append(str(cross_val_score(regr, toy_data.data, toy_data.target).mean()))                \n",
    "            self.historical_points.append(','.join([str(x) for x in r]))\n",
    "\n",
    "    def test_points(self, next_points):\n",
    "        \n",
    "        for nxt_pt in [p.split(',') for p in next_points['next_points'].split(';')]:\n",
    "            if self.model == 'ElasticNet':\n",
    "                regr = ElasticNet(alpha = float(nxt_pt[0]), l1_ratio=float(nxt_pt[1]))\n",
    "            elif self.model == 'SVR':\n",
    "                regr = make_pipeline(StandardScaler(), SVR(C = float(nxt_pt[0]), epsilon=float(nxt_pt[1])))\n",
    "            elif self.model == 'XGBoost':\n",
    "                regr = XGBClassifier(gamma=nxt_pt[0], reg_lambda=nxt_pt[1], colsample_bytree=nxt_pt[2], \n",
    "                                     max_depth=nxt_pt[3], min_child_weight=nxt_pt[4], learning_rate=nxt_pt[5])          \n",
    "            regr.fit(self.X_train, self.y_train)\n",
    "            if self.target_type == 'regression':\n",
    "                self.historical_scores.append(str(r2_score(self.y_test, regr.predict(self.X_test))))\n",
    "            else:\n",
    "                self.historical_scores.append(str(cross_val_score(regr, self.data, self.target).mean()))               \n",
    "                \n",
    "        self.historical_points += next_points['next_points'].split(';')\n",
    "        \n",
    "    def get_best_point(self):\n",
    "        \n",
    "        if self.target_type == 'regression':\n",
    "            best = 1000\n",
    "        else:\n",
    "            best = -1\n",
    "            \n",
    "        best_point = 'failed'\n",
    "        for s, pt in zip(qc_bo.historical_scores, qc_bo.historical_points):\n",
    "            if self.metric(float(s),  best):\n",
    "                best = float(s)\n",
    "                best_point = pt\n",
    "        return(best_point)\n",
    "    \n",
    "    def create_url (self):\n",
    "\n",
    "        if self.target_type == 'regression':\n",
    "            # if lower score is better (rmse, r2, etc)\n",
    "            data = json.dumps({'scores': ','.join([str(1-float(s)) for s in self.historical_scores]), 'points': ';'.join(self.historical_points)})\n",
    "        else:\n",
    "            data = json.dumps({'scores': ','.join(self.historical_scores), 'points': ';'.join(self.historical_points)})\n",
    "        \n",
    "        y_best = 10\n",
    "        hp_ranges_str = ';'.join([','.join([str(x) for x in s]) for s in self.hp_ranges])\n",
    "        hp_types_str = ','.join(self.hp_types)\n",
    "        stem = \"http://localhost:8000/bayes_opt?hp_types=\"\n",
    "        url = stem + \"{}&g_batch_size={}&hp_ranges={}&y_best={}&n_gpus={}&use_qc={}\".format(hp_types_str, self.gbr_batch_size, \n",
    "                                                                                               hp_ranges_str, y_best, self.n_procs, 'False')\n",
    "        return url, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055c145-8d11-4349-b379-eb4b3bea9503",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a85679-0d09-4d88-99f0-a8673f4617ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bo = bayes_optimization_example(30, 4, 'EN')\n",
    "hp_types = ['float', 'float']\n",
    "hp_ranges =  [[0.0001,.99999],[0.0001,.99999]]\n",
    "qc_bo.initialize(diabetes, hp_types, hp_ranges)\n",
    "historical_qei = []\n",
    "best_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7990d6-d048-40e3-886f-67cc4e2fbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(50):\n",
    "    url, data = qc_bo.create_url() # using historical data\n",
    "    response = requests.post(url, data=data)\n",
    "    next_points = json.loads(response.text)\n",
    "    historical_qei.append(next_points['best_ccdf'])\n",
    "    qc_bo.test_points(next_points)\n",
    "    best_points.append(qc_bo.get_best_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45cb50-616f-441a-8c9a-855cc52dae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [np.log(float(q)) for q in qc_bo.historical_scores]\n",
    "best = 10\n",
    "best_so_far = []\n",
    "for q in qc_bo.historical_scores:\n",
    "    if np.log(float(q))< best:\n",
    "        best = np.log(float(q))\n",
    "    best_so_far.append(best)\n",
    "plt.plot(h)\n",
    "plt.plot(best_so_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082362b0-88b5-4418-899e-b31a534bddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when parameters changed\n",
    "plt.plot([float(b.split(',')[0]) for b in best_points], label='alpha')\n",
    "plt.plot([float(b.split(',')[1]) for b in best_points], label='l1_ratio')\n",
    "p = plt.legend()\n",
    "qc_bo.get_best_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf89538-3247-4757-9501-75a1a3ff2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historical_qei)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ea93f-ddd8-42c2-9895-cd87a95c448a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Support Vector Regression\n",
    "C, \n",
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263a208-2701-4235-9001-91a563c3fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bo = bayes_optimization_example(30, 4, 'SVR')\n",
    "hp_types = ['float', 'float']\n",
    "hp_ranges =  [[0.1,10],[0.001,.999]]\n",
    "qc_bo.initialize(diabetes, hp_types, hp_ranges)\n",
    "historical_qei = []\n",
    "best_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821e10e-c1de-4b88-b0a1-79d32acafebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(50):\n",
    "    url, data = qc_bo.create_url() # using historical data\n",
    "    response = requests.post(url, data=data)\n",
    "    next_points = json.loads(response.text)\n",
    "    historical_qei.append(next_points['best_ccdf'])\n",
    "    qc_bo.test_points(next_points)\n",
    "    best_points.append(qc_bo.get_best_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3eb3e-a808-4bc8-ae8d-a624f99921b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when parameters changed\n",
    "plt.plot([float(b.split(',')[0]) for b in best_points], label='C')\n",
    "plt.plot([float(b.split(',')[1]) for b in best_points], label='epsilon')\n",
    "p = plt.legend()\n",
    "qc_bo.get_best_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6ed10-8cda-4ed2-853e-b2740aa5e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [np.log(float(q)) for q in qc_bo.historical_scores]\n",
    "best = 10\n",
    "best_so_far = []\n",
    "for q in qc_bo.historical_scores:\n",
    "    if np.log(float(q))< best:\n",
    "        best = np.log(float(q))\n",
    "    best_so_far.append(best)\n",
    "plt.plot(h)\n",
    "plt.plot(best_so_far)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37db96-bbfd-4676-b409-93b8e482926c",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea2366-b7fe-445b-8ebf-e940b84627ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### One hot encoding for digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1ebe1-5d91-4393-a350-94659e89b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(digits.target.reshape(-1,1))\n",
    "enc.categories_\n",
    "ohe_target = enc.transform(digits.target.reshape(-1, 1))\n",
    "#enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67449e5e-ccb2-49f3-b4a2-45488a2412f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bunch:\n",
    "    def __init__(self, d):\n",
    "        self.data = d['data']\n",
    "        self.target = d['target']\n",
    "        \n",
    "digits_bunch= bunch({'target': ohe_target,\n",
    "                     'data': digits.data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39981b68-281c-43f1-9ca8-12178e8a7eb1",
   "metadata": {},
   "source": [
    "### Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312eba9-3e70-46ef-92e0-ce071bbfd7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bo = bayes_optimization_example(300, 4, 'XGBoost')\n",
    "\n",
    "parameter_names = ['gamma', 'reg_lambda', 'colsample_by_tree',\n",
    "                   'max_depth', 'min_child_weight', 'learning_rate']\n",
    "\n",
    "hp_types = ['float', 'float', 'float',  'int', 'float', 'float']\n",
    "hp_ranges =  [[0.01, .999],[0.001,.999], [0.001,.999],\n",
    "              [2, 5],[0.001,.999] ,[0.001,.999]]\n",
    "\n",
    "qc_bo.initialize(breast_cancer, hp_types, hp_ranges)\n",
    "historical_qei = []\n",
    "best_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1aaab0-12eb-4d57-8201-b89c0c1369b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(100):\n",
    "    url, data = qc_bo.create_url() # using historical data\n",
    "    start = time.time()\n",
    "    response = requests.post(url, data=data)\n",
    "    print(\"{}: Spent {} seconds getting next points\".format(a, round(time.time()-start,3)))\n",
    "    next_points = json.loads(response.text)\n",
    "    historical_qei.append(next_points['best_ccdf'])\n",
    "    qc_bo.test_points(next_points)\n",
    "    best_points.append(qc_bo.get_best_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef325d-f7d4-4a47-a637-2fe576bc43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class use_log:\n",
    "    def __init__(self, log_or_not):\n",
    "        self.log_or_not = log_or_not\n",
    "    def log(self, x):\n",
    "        if self.log_or_not:\n",
    "            return np.log(x)\n",
    "        else:\n",
    "            return (x)\n",
    "def show_results(session, log):\n",
    "    u = use_log(log)\n",
    "    h = [u.log(float(q)) for q in session.historical_scores]\n",
    "    print(\"average performance (during bo)               {}\".format(np.mean([float(q) for q in session.historical_scores])))\n",
    "    print(\"standard deviation of performance (during bo) {}\".format(np.std([float(q) for q in session.historical_scores])))\n",
    "    if session.target_type == 'regression':\n",
    "        best = 10\n",
    "    else:\n",
    "        best = -1\n",
    "    \n",
    "    best_so_far = []\n",
    "    for q in session.historical_scores:\n",
    "        if session.metric(u.log(float(q)), best):\n",
    "            best = u.log(float(q))\n",
    "        best_so_far.append(best)\n",
    "    plt.plot(h, label='historical')\n",
    "    plt.plot(best_so_far, label='best_so_far')\n",
    "    p = plt.legend()\n",
    "    print(\"Best after BO {}\".format(best))\n",
    "show_results(qc_bo, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d20de-a469-4011-9c3f-f9be862a2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(p)+': '+z for p, z in zip(parameter_names, qc_bo.get_best_point().split(','))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dbcc9e-10e8-47cb-baf0-2e423adfd777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f76c6-9f6b-4838-8f54-1b67016726d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-venv",
   "language": "python",
   "name": "base-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
