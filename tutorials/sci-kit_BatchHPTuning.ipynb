{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6369e92b-8114-4736-8782-2448501e0b5b",
   "metadata": {},
   "source": [
    "# How to do batch hyperparmaeter tuning with sci-kit using quante_carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0dafc-f071-4050-9398-7c18ea8a0fbe",
   "metadata": {},
   "source": [
    "This is a demonstration that trains sci-kit models on toy datasets and makes reuqests to bayesian optimization as a service for hyperparameter tuning.<br>\n",
    "Note to person giving demo:<br>\n",
    "    <code>gunicorn -w 18 'flask_worker:app'</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec63643-7bfb-4dbe-9d9f-5c899754017e",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eeda8c-b6f8-4677-8b2f-70c235e4c186",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e12e8-423a-4723-a98e-d75352e44b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json\n",
    "import random\n",
    "from sklearn.datasets import load_diabetes, load_digits, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "diabetes = load_diabetes()\n",
    "digits = load_diabetes()\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c12f2-154b-4401-920b-8dfc2ae28436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218660bf-6f74-4e48-a8b3-990c93b0edf5",
   "metadata": {},
   "source": [
    "### User defined module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab565e5-97d3-41df-8726-16efc030fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bayes_optimization_example:\n",
    "    def __init__(self, gbr_batch_size, n_processors, model):\n",
    "        self.n_procs = n_processors\n",
    "        self.gbr_batch_size = gbr_batch_size # how many points to evaluate when optimizing gaussian process\n",
    "        self.model = model\n",
    "\n",
    "    def metric(self, x, y):\n",
    "        if self.target_type == 'regression':\n",
    "            if x < y:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            if x > y:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def initialize(self, toy_data, hp_types, hp_ranges):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(toy_data.data, toy_data.target, test_size=0.5, random_state=42)\n",
    "        self.data = toy_data.data\n",
    "        self.target = toy_data.target\n",
    "        self.hp_types = hp_types\n",
    "        self.historical_scores = []\n",
    "        self.historical_points = []\n",
    "        self.hp_ranges = hp_ranges\n",
    "        for a in range(10):\n",
    "            r = [random.uniform(hp_ranges[x][0], hp_ranges[x][1]) \n",
    "                 if hp_types[x] == 'float' else random.randint(hp_ranges[x][0], hp_ranges[x][1]) \n",
    "                 for x in range(len(hp_ranges))]\n",
    "            if self.model == 'ElasticNet':\n",
    "                self.target_type = 'regression'\n",
    "                model = ElasticNet(alpha = r[0], l1_ratio=r[1])\n",
    "            elif self.model == 'SVR':\n",
    "                self.target_type = 'regression'\n",
    "                model = make_pipeline(StandardScaler(), SVR(C=r[0], epsilon=r[1]))\n",
    "            elif self.model == 'XGBoostClassifier':\n",
    "                self.target_type = 'classification'\n",
    "                model = XGBClassifier(gamma=r[0], reg_lambda=r[1], colsample_bytree=r[2], \n",
    "                                     max_depth=r[3], min_child_weight=r[4], learning_rate=r[5])\n",
    "            elif self.model == 'XGBoostRegressor':\n",
    "                self.target_type = 'regression'\n",
    "                model = XGBRegressor(gamma=r[0], reg_lambda=r[1], colsample_bytree=r[2], \n",
    "                                     max_depth=r[3], min_child_weight=r[4], learning_rate=r[5])\n",
    "\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            if self.target_type == 'regression':\n",
    "                self.historical_scores.append(str(r2_score(self.y_test, model.predict(self.X_test))))\n",
    "            else:\n",
    "                self.historical_scores.append(str(cross_val_score(model, toy_data.data, toy_data.target).mean()))                \n",
    "            self.historical_points.append(','.join([str(x) for x in r]))\n",
    "\n",
    "    def test_points(self, next_points):\n",
    "        \n",
    "        for nxt_pt in [p.split(',') for p in next_points['next_points'].split(';')]:\n",
    "            if self.model == 'ElasticNet':\n",
    "                model = ElasticNet(alpha = float(nxt_pt[0]), l1_ratio=float(nxt_pt[1]))\n",
    "            elif self.model == 'SVR':\n",
    "                model = make_pipeline(StandardScaler(), SVR(C = float(nxt_pt[0]), epsilon=float(nxt_pt[1])))\n",
    "            elif self.model == 'XGBoostClassifier':\n",
    "                model = XGBClassifier(gamma=nxt_pt[0], reg_lambda=nxt_pt[1], colsample_bytree=nxt_pt[2], \n",
    "                                     max_depth=nxt_pt[3], min_child_weight=nxt_pt[4], learning_rate=nxt_pt[5])   \n",
    "            elif self.model == 'XGBoostRegressor':\n",
    "                model = XGBRegressor(gamma=nxt_pt[0], reg_lambda=nxt_pt[1], colsample_bytree=nxt_pt[2], \n",
    "                                     max_depth=nxt_pt[3], min_child_weight=nxt_pt[4], learning_rate=nxt_pt[5])\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            if self.target_type == 'regression':\n",
    "                self.historical_scores.append(str(r2_score(self.y_test, model.predict(self.X_test))))\n",
    "            else:\n",
    "                self.historical_scores.append(str(cross_val_score(model, self.data, self.target).mean()))               \n",
    "                \n",
    "        self.historical_points += next_points['next_points'].split(';')\n",
    "        \n",
    "    def get_best_point(self):\n",
    "        \n",
    "        if self.target_type == 'regression':\n",
    "            best = 1000\n",
    "        else:\n",
    "            best = -1\n",
    "            \n",
    "        best_point = 'failed'\n",
    "        for s, pt in zip(qc_bo.historical_scores, qc_bo.historical_points):\n",
    "            if self.metric(float(s),  best):\n",
    "                best = float(s)\n",
    "                best_point = pt\n",
    "        return(best_point)\n",
    "    \n",
    "    def create_url (self):\n",
    "\n",
    "        if self.target_type == 'regression':\n",
    "            # if lower score is better (rmse, r2, etc)\n",
    "            h_scores = [float(s) for s in self.historical_scores]\n",
    "            mx = np.max(h_scores)\n",
    "            data = json.dumps({'scores': ','.join([str(1+mx-s) for s in h_scores]), 'points': ';'.join(self.historical_points)})\n",
    "        else:\n",
    "            data = json.dumps({'scores': ','.join(self.historical_scores), 'points': ';'.join(self.historical_points)})\n",
    "        \n",
    "        y_best = 10\n",
    "        hp_ranges_str = ';'.join([','.join([str(x) for x in s]) for s in self.hp_ranges])\n",
    "        hp_types_str = ','.join(self.hp_types)\n",
    "        stem = \"http://localhost:8000/bayes_opt?hp_types=\"\n",
    "        url = stem + \"{}&g_batch_size={}&hp_ranges={}&y_best={}&n_gpus={}&use_qc={}\".format(hp_types_str, self.gbr_batch_size, \n",
    "                                                                                               hp_ranges_str, y_best, self.n_procs, 'False')\n",
    "        return url, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c521f7d-ff87-407f-936d-62ed24a81625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class use_log:\n",
    "    def __init__(self, log_or_not):\n",
    "        self.log_or_not = log_or_not\n",
    "    def log(self, x):\n",
    "        if self.log_or_not:\n",
    "            return np.log(x)\n",
    "        else:\n",
    "            return (x)\n",
    "def show_results(session, log):\n",
    "    u = use_log(log)\n",
    "    h = [u.log(float(q)) for q in session.historical_scores]\n",
    "    print(\"average performance (during bo)               {}\".format(np.mean([float(q) for q in session.historical_scores])))\n",
    "    print(\"standard deviation of performance (during bo) {}\".format(np.std([float(q) for q in session.historical_scores])))\n",
    "    if session.target_type == 'regression':\n",
    "        best = 10\n",
    "    else:\n",
    "        best = -1\n",
    "    \n",
    "    best_so_far = []\n",
    "    for q in session.historical_scores:\n",
    "        if session.metric(u.log(float(q)), best):\n",
    "            best = u.log(float(q))\n",
    "        best_so_far.append(best)\n",
    "    plt.plot(h, label='historical')\n",
    "    plt.plot(best_so_far, label='best_so_far')\n",
    "    p = plt.legend()\n",
    "    print(\"Best after BO {}\".format(best))\n",
    "\n",
    "class bunch:\n",
    "    def __init__(self, d):\n",
    "        self.data = d['data']\n",
    "        self.target = d['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055c145-8d11-4349-b379-eb4b3bea9503",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a85679-0d09-4d88-99f0-a8673f4617ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bo = bayes_optimization_example(30, 4, 'EN')\n",
    "hp_types = ['float', 'float']\n",
    "hp_ranges =  [[0.0001,.99999],[0.0001,.99999]]\n",
    "qc_bo.initialize(diabetes, hp_types, hp_ranges)\n",
    "historical_qei = []\n",
    "best_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7990d6-d048-40e3-886f-67cc4e2fbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(50):\n",
    "    url, data = qc_bo.create_url() # using historical data\n",
    "    response = requests.post(url, data=data)\n",
    "    next_points = json.loads(response.text)\n",
    "    historical_qei.append(next_points['best_ccdf'])\n",
    "    qc_bo.test_points(next_points)\n",
    "    best_points.append(qc_bo.get_best_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45cb50-616f-441a-8c9a-855cc52dae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [np.log(float(q)) for q in qc_bo.historical_scores]\n",
    "best = 10\n",
    "best_so_far = []\n",
    "for q in qc_bo.historical_scores:\n",
    "    if np.log(float(q))< best:\n",
    "        best = np.log(float(q))\n",
    "    best_so_far.append(best)\n",
    "plt.plot(h)\n",
    "plt.plot(best_so_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082362b0-88b5-4418-899e-b31a534bddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when parameters changed\n",
    "plt.plot([float(b.split(',')[0]) for b in best_points], label='alpha')\n",
    "plt.plot([float(b.split(',')[1]) for b in best_points], label='l1_ratio')\n",
    "p = plt.legend()\n",
    "qc_bo.get_best_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf89538-3247-4757-9501-75a1a3ff2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historical_qei)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ea93f-ddd8-42c2-9895-cd87a95c448a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Support Vector Regression\n",
    "C, \n",
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263a208-2701-4235-9001-91a563c3fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bo = bayes_optimization_example(30, 4, 'SVR')\n",
    "hp_types = ['float', 'float']\n",
    "hp_ranges =  [[0.1,10],[0.001,.999]]\n",
    "qc_bo.initialize(diabetes, hp_types, hp_ranges)\n",
    "historical_qei = []\n",
    "best_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821e10e-c1de-4b88-b0a1-79d32acafebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(50):\n",
    "    url, data = qc_bo.create_url() # using historical data\n",
    "    response = requests.post(url, data=data)\n",
    "    next_points = json.loads(response.text)\n",
    "    historical_qei.append(next_points['best_ccdf'])\n",
    "    qc_bo.test_points(next_points)\n",
    "    best_points.append(qc_bo.get_best_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3eb3e-a808-4bc8-ae8d-a624f99921b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when parameters changed\n",
    "plt.plot([float(b.split(',')[0]) for b in best_points], label='C')\n",
    "plt.plot([float(b.split(',')[1]) for b in best_points], label='epsilon')\n",
    "p = plt.legend()\n",
    "qc_bo.get_best_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6ed10-8cda-4ed2-853e-b2740aa5e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [np.log(float(q)) for q in qc_bo.historical_scores]\n",
    "best = 10\n",
    "best_so_far = []\n",
    "for q in qc_bo.historical_scores:\n",
    "    if np.log(float(q))< best:\n",
    "        best = np.log(float(q))\n",
    "    best_so_far.append(best)\n",
    "plt.plot(h)\n",
    "plt.plot(best_so_far)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37db96-bbfd-4676-b409-93b8e482926c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea2366-b7fe-445b-8ebf-e940b84627ca",
   "metadata": {},
   "source": [
    "### One hot encoding for digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1ebe1-5d91-4393-a350-94659e89b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(digits.target.reshape(-1,1))\n",
    "enc.categories_\n",
    "ohe_target = enc.transform(digits.target.reshape(-1, 1))\n",
    "#enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67449e5e-ccb2-49f3-b4a2-45488a2412f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_bunch= bunch({'target': ohe_target,\n",
    "                     'data': digits.data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39981b68-281c-43f1-9ca8-12178e8a7eb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312eba9-3e70-46ef-92e0-ce071bbfd7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bo = bayes_optimization_example(300, 4, 'XGBoost')\n",
    "\n",
    "parameter_names = ['gamma', 'reg_lambda', 'colsample_by_tree',\n",
    "                   'max_depth', 'min_child_weight', 'learning_rate']\n",
    "\n",
    "hp_types = ['float', 'float', 'float',  'int', 'float', 'float']\n",
    "hp_ranges =  [[0.01, .999],[0.001,.999], [0.001,.999],\n",
    "              [2, 5],[0.001,.999] ,[0.001,.999]]\n",
    "\n",
    "qc_bo.initialize(breast_cancer, hp_types, hp_ranges)\n",
    "historical_qei = []\n",
    "best_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1aaab0-12eb-4d57-8201-b89c0c1369b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(100):\n",
    "    url, data = qc_bo.create_url() # using historical data\n",
    "    start = time.time()\n",
    "    response = requests.post(url, data=data)\n",
    "    print(\"{}: Spent {} seconds getting next points\".format(a, round(time.time()-start,3)))\n",
    "    next_points = json.loads(response.text)\n",
    "    historical_qei.append(next_points['best_ccdf'])\n",
    "    qc_bo.test_points(next_points)\n",
    "    best_points.append(qc_bo.get_best_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef325d-f7d4-4a47-a637-2fe576bc43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_results(qc_bo, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d20de-a469-4011-9c3f-f9be862a2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(p)+': '+z for p, z in zip(parameter_names, qc_bo.get_best_point().split(','))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adbea8-7dff-4ba2-b982-ef8d4204b768",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f76c6-9f6b-4838-8f54-1b67016726d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bo = bayes_optimization_example(300, 4, 'XGBoostRegressor')\n",
    "\n",
    "parameter_names = ['gamma', 'reg_lambda', 'colsample_by_tree',\n",
    "                   'max_depth', 'min_child_weight', 'learning_rate']\n",
    "\n",
    "hp_types = ['float', 'float', 'float',  'int', 'float', 'float']\n",
    "hp_ranges =  [[0.01, .999],[0.001,.999], [0.001,.999],\n",
    "              [2, 5],[0.001,.999] ,[0.001,.999]]\n",
    "\n",
    "qc_bo.initialize(diabetes, hp_types, hp_ranges)\n",
    "historical_qei = []\n",
    "best_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf7a269-f200-45a7-8100-807311a254fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(10):\n",
    "    url, data = qc_bo.create_url() # using historical data\n",
    "    start = time.time()\n",
    "    response = requests.post(url, data=data)\n",
    "    print(\"{}: Spent {} seconds getting next points\".format(a, round(time.time()-start,3)))\n",
    "    next_points = json.loads(response.text)\n",
    "    historical_qei.append(next_points['best_ccdf'])\n",
    "    qc_bo.test_points(next_points)\n",
    "    best_points.append(qc_bo.get_best_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05fa8e-a57c-4a76-8a4a-02b6ca6e041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(qc_bo, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ad900-90ce-4382-8d27-7513b9062b18",
   "metadata": {},
   "source": [
    "## NVIDIA Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acad54-8a5b-4a71-8e16-7332794748cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_df = pd.read_csv('sampledata.csv')\n",
    "continuous_predictors = nvidia_df.columns[4:]\n",
    "categorical = ['trickortreat', 'kingofhalloween']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3f8bf-14ae-406f-b479-ea6b1371a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(nvidia_df[categorical])\n",
    "categorical_df = enc.transform(nvidia_df[categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad8bab-6e89-40dc-bdd3-0dc564ed6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(categorical_df, nvidia_df['y'])\n",
    "leaf_ids = tree.apply(categorical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791f659-a61f-46fc-b2b1-e591fba96310",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(nvidia_df[categorical])\n",
    "categorical_df = enc.transform(nvidia_df[categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653406d7-cbe9-4599-8b5c-6c7b58945c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nvidia_df[continuous_predictors].copy()\n",
    "df['dtree_id'] = leaf_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d322ec0-de18-47c2-8065-cccd2be905f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bo = bayes_optimization_example(300, 4, 'XGBoostRegressor')\n",
    "\n",
    "parameter_names = ['gamma', 'reg_lambda', 'colsample_by_tree',\n",
    "                   'max_depth', 'min_child_weight', 'learning_rate']\n",
    "\n",
    "hp_types = ['float', 'float', 'float',  'int', 'float', 'float']\n",
    "hp_ranges =  [[0.01, .999],[0.001,.999], [0.001,.999],\n",
    "              [2, 5],[0.001,.999] ,[0.001,.999]]\n",
    "\n",
    "qc_bo.initialize(bunch({'data': df, 'target': nvidia_df['y']}), hp_types, hp_ranges)\n",
    "historical_qei = []\n",
    "best_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b74a1-ad20-4f8f-9db0-c63070101dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(10):\n",
    "    url, data = qc_bo.create_url() # using historical data\n",
    "    start = time.time()\n",
    "    response = requests.post(url, data=data)\n",
    "    print(\"{}: Spent {} seconds getting next points\".format(a, round(time.time()-start,3)))\n",
    "    next_points = json.loads(response.text)\n",
    "    historical_qei.append(next_points['best_ccdf'])\n",
    "    qc_bo.test_points(next_points)\n",
    "    best_points.append(qc_bo.get_best_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc76594-8ba5-4c3b-8d79-be5844a2e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(qc_bo, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d4d14-776d-4d71-a273-6a547b88f0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-venv",
   "language": "python",
   "name": "base-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
