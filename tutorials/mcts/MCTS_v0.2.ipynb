{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd18900-31b9-489d-9756-37c559f60753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor, kernels\n",
    "from time import time\n",
    "import requests\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import mc\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966de08-0a57-4b0a-a17a-ab817b9998d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfc63c-cc04-4f06-ac7b-5e9380f0f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expand_single(root, n_simulations, use_bo=False, gpr=None, parallel=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Does two things sequentially, each in parallel\n",
    "    - GPR predict\n",
    "    - Monte Carlo\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings, scores, next_moves, next_move_ndx = root.depth_first_search_gp()\n",
    "    \n",
    "    if use_bo:\n",
    "        next_embedding = [e.game_embedding for e in next_moves]\n",
    "        if parallel:\n",
    "            needs_mc = []\n",
    "\n",
    "            # gets batches\n",
    "            for i in range(parallel['n_parallel']):\n",
    "                needs_mc.append({'N': n_simulations, \n",
    "                                 'n_gpr_samples': parallel['n_gpr_samples'],\n",
    "                                 'n_parallel': parallel['n_parallel'],\n",
    "                                 'root': root, 'id': i,\n",
    "                                 'gpr_url': 'http://localhost:8100/gpr?reload={}&gpr_path={}'.format(parallel['reload'], parallel['pickle_path']),\n",
    "                                 'mpi_url': 'http://localhost:8080/mpi'}) \n",
    "            results = parallel['pool'].map(parallel['gpr_worker'], needs_mc)\n",
    "            mpi = [x[1] for x in results]\n",
    "            mx = max(mpi)\n",
    "            ndx = mpi.index(mx)\n",
    "   \n",
    "            # runs monte carlo\n",
    "            results = parallel['pool'].map(parallel['mc_worker'], \n",
    "                                           [{'move': move, 'n_simulations': parallel['n_simulations']} for move in results[ndx][0]])\n",
    "                            \n",
    "            return results\n",
    "           \n",
    "        else:\n",
    "            predictions, sigma = gpr.predict(next_embedding, return_std=True )\n",
    "            ucb = [p + 1.96 * s for p, s in zip(predictions, sigma)]\n",
    "            lcb = [p - 1.96 * s for p, s in zip(predictions, sigma)]\n",
    "            mx = max(ucb)\n",
    "            mn = min(lcb)\n",
    "            if np.abs(mx) > np.abs(mn):\n",
    "                new_move_ndx = list(ucb).index(mx)\n",
    "            else:\n",
    "                new_move_ndx = list(lcb).index(mn)\n",
    "    else:\n",
    "        new_move_ndx = random.randint(0, len(next_moves)-1)\n",
    "        \n",
    "    move = next_moves.pop(new_move_ndx)\n",
    "    parent = move.parent\n",
    "    parent.children.append(mc.Node(move.game.copy(), move.x, move.y))\n",
    "    parent.children[-1].scores = parent.children[-1].MC(n_simulations)\n",
    "    parent.children[-1].calculate_score()\n",
    "    return parent.possible_next_moves.pop(next_move_ndx[new_move_ndx]) # remove it from it's original spot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf757198-4a4b-4b65-870c-e71639059534",
   "metadata": {},
   "source": [
    "## Game Play\n",
    "Functions that plays the oppoent's move and expands nodes in the tree\n",
    "- when repeating, start over with a clean slate of 'next moves'\n",
    "- it doesn't help for this to build up 'possible next moves' indefinitely\n",
    "- we can keep the embedding, score pairs though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf310758-c5aa-483d-b4e9-8d89f90e3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def learning(master_game, n_children, n_simulations, \n",
    "                  n_expansions, use_bo, gpr, parallelization=None):\n",
    "    \"\"\" \n",
    "    Other player moves and children have random expansion\n",
    "    - there's no gaurantee that the other player's move is one that is in the system\n",
    "    - for now, it's easier to just randomly expand it\n",
    "    \"\"\"\n",
    "    \n",
    "    x, y = master_game.get_random_move() # O moves at random\n",
    "    print('Other player moves at random {} {}'.format(x, y))\n",
    "    master_game.place_stone(x, y)\n",
    "    MCTS = mc.Node(master_game, x, y)\n",
    "    \n",
    "    MCTS.expand(n_children) \n",
    "    \n",
    "    for c in MCTS.children:\n",
    "        c.scores = c.MC(n_simulations)\n",
    "        c.calculate_score()\n",
    "        \n",
    "    print('Expanding')    \n",
    "    for a in range(n_expansions):\n",
    "        if not a % 5:\n",
    "            print('  ' + str(a))\n",
    "        move = expand_single(MCTS, n_simulations, use_bo, gpr, parallelization)\n",
    "        \n",
    "    return MCTS\n",
    "\n",
    "def play_best_move(master_game, MCTS):\n",
    "    \n",
    "    best_node, best_x, best_y, win_probability = MCTS.depth_first_search_move()\n",
    "    print('Playing best move {} {} with win probability {}'.format(best_x, best_y,round(win_probability, 4)))\n",
    "\n",
    "    master_game.place_stone(best_x, best_y)\n",
    "    print(\"N Moves {}\\n{} of player 1's pieces captured\\n{} of player 2's pieces captured\".format(master_game.n_moves, master_game.n_captured[1], master_game.n_captured[2]))\n",
    "    master_game.print_board()\n",
    "    return master_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26811e-4b07-4feb-a4b1-5705ba1ba52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimization approach\n",
    "# for next expansion\n",
    "\n",
    "def probability_integral_transform(embeddings, scores):\n",
    "    # convert to normal distribution\n",
    "\n",
    "    df = pd.DataFrame({'embedding': embeddings, 'probability': scores})\n",
    "    df = df[df['probability'] >= 0].sort_values('probability')\n",
    "    adj = 1/(2*df.shape[0])\n",
    "\n",
    "    df['standard_normal'] = [norm.ppf(i/df.shape[0]+adj) for i, x in enumerate(df['probability'])]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fit_BO(MCTS, saved_embeddings, saved_scores):\n",
    "\n",
    "\n",
    "    embeddings, scores, next_moves, next_move_ndx = MCTS.depth_first_search_gp()\n",
    "    print(\"{} next moves this round.\".format(len(next_moves)))\n",
    "\n",
    "    embeddings += saved_embeddings\n",
    "    scores += saved_scores\n",
    "    gpr = GaussianProcessRegressor(kernels.Matern() + kernels.WhiteKernel(), copy_X_train=False)\n",
    "    start = time()\n",
    "    df = probability_integral_transform(embeddings, scores)\n",
    " \n",
    "    gpr.fit([e for e in df['embedding']], df['standard_normal'])\n",
    "    print(\"Fitting GPR took {} seconds\".format(round(time()-start, 4)))\n",
    "    next_embedding = [e.game_embedding for e in next_moves]\n",
    "    predictions, sigma = gpr.predict(next_embedding, return_std=True )\n",
    "    print(\"{} total embeddings for GPR model\".format(len(embeddings)))\n",
    "    return embeddings, scores, gpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792a10c-3abb-4257-874a-1a494a6c59fe",
   "metadata": {},
   "source": [
    "## Initialize with no GPR and no parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593d92a-fc76-47e8-9fa3-71ff24844191",
   "metadata": {},
   "outputs": [],
   "source": [
    "MasterGame = mc.GoGame(9)\n",
    "saved_scores = []\n",
    "saved_embeddings = []\n",
    "n_children = 7           # opponent random\n",
    "n_simulations = 13\n",
    "use_bo = False\n",
    "n_expansions = 11        # if parallel, you don't need many\n",
    "gpr = None\n",
    "MCTS = learning(MasterGame, n_children, n_simulations, n_expansions, use_bo, gpr)\n",
    "mg = play_best_move(MasterGame, MCTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb48ed-a384-45ed-95d3-6a148d287f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.close()\n",
    "p = mp.Pool(4)\n",
    "parallel = {'n_gpr_samples': 200,\n",
    "            'n_parallel': 4,\n",
    "            'y_best': np.sqrt(2),\n",
    "            'gpr_worker': mc.get_best_batch,\n",
    "            'mc_worker': mc.simulations,\n",
    "            'n_simulations': n_simulations,\n",
    "            'reload': 'True',\n",
    "            'pickle_path': 'gpr.pkl',\n",
    "            'pool': p}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e624f-7cf1-4d95-8f3e-7619625c41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! TODO: MPI is for player 2 only\n",
    "# should incorporate different measure for player 1\n",
    "\n",
    "print('Simulating')\n",
    "for iteration in range(6):\n",
    "    print(\"Play Turn and Expand {}\".format(iteration))\n",
    "    \n",
    "    MCTS = learning(MasterGame, n_children, n_simulations, n_expansions, use_bo, gpr, parallel)\n",
    "    parallel['reload'] = 'False'\n",
    "\n",
    "    print(\"Getting Best Move\")\n",
    "    mg = play_best_move(MasterGame, MCTS)\n",
    "    if not iteration % 4:\n",
    "        print(\"Fitting GPR\")\n",
    "        saved_embeddings, saved_scores, gpr = fit_BO(MCTS, saved_embeddings, saved_scores)\n",
    "        \n",
    "        with open(parallel['pickle_path'], 'wb') as m:\n",
    "            pickle.dump(gpr, m)\n",
    "\n",
    "        use_bo = True\n",
    "        parallel['reload'] = 'True'\n",
    "    \n",
    "    else:\n",
    "        print(\"Not refitting. Just saving.\")\n",
    "        embeddings, scores, next_moves, next_move_ndx = MCTS.depth_first_search_gp()\n",
    "        saved_embeddings += embeddings\n",
    "        saved_scores += scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac565eb-30c9-4fa0-baaa-9f29796f7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.close()\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a437543-7353-4a1b-8dd6-60a09ac43264",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030bd18a-644c-4f08-b648-66eb4976583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mp.Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648bd5e2-a472-4355-af4b-6532bd8e3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings, scores, next_moves, next_move_ndx = MCTS.depth_first_search_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077c00c-09c4-49ce-acd6-8fd47ec32f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_of_batches = []\n",
    "for x in range(4):\n",
    "    batches = []\n",
    "    for x in range(100):\n",
    "        batch = [next_moves[random.randint(0, len(next_moves)-1)].game_embedding for y in range(4)]\n",
    "        batches.append(batch.copy())\n",
    "    batch_of_batches.append({'gpr_pickle': 'gpr.pkl', 'batches': batches.copy()})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84d098-144b-45cd-839a-9d5413c5a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "results = p.map(mc.gpr_predict, batch_of_batches)\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c184ea-86d8-4d72-ba88-a1c3150d5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(len(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b367f-412d-4f43-bd72-6b9b0d12ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:8100/gpr'\n",
    "len(string_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c801624-5e60-45c8-a8df-da6bbcef97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_batches = []\n",
    "for b in batches:\n",
    "    string_batches.append(';'.join([','.join([str(x) for x in v]) for v in b]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2ec73-601c-4912-89fc-146c9d5e0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "response = json.loads(requests.post(url=url, data=json.dumps({'batches': '|'.join(string_batches)})).content)\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb4e45-111f-4a53-860e-36a792a262b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = response['covariances'].split('|')[0].split(';')\n",
    "[[float(x) for x in r.split(',')] for r in cv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c5e0f-7b61-4a1b-88c7-87103c50a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8142c85-9b16-4bda-b24c-acede94917ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-venv",
   "language": "python",
   "name": "base-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
