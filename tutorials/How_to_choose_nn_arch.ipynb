{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ad6ad1-9b33-4fe1-b780-02f89f558226",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial for quante_carlo\n",
    "- <b>quante_carlo</b> is a multiprocess hyperparameter tuning module. \n",
    "- This notebook demonstrates how to use this module to determine the number of neurons to use in a pytorch neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163aa4c-a7c7-4741-b4c0-52fcd6d55634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from quante_carlo import hp_tune\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from torch import nn\n",
    "import neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e65830-1a99-4b25-80c6-76e0ee17c0a4",
   "metadata": {},
   "source": [
    "## This tutorial uses mnist dataset available <a href=\"https://www.kaggle.com/code/imdevskp/digits-mnist-classification-using-cnn\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f75894-f21c-4e94-abcd-7e3401261dce",
   "metadata": {},
   "source": [
    "### Multiprocessing\n",
    "This uses multiprocessing to train. Each process interacts with the Bayesian Optimization API individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26666ddd-5a79-472c-9a7a-13c768eb1213",
   "metadata": {},
   "source": [
    "Included with this repository is a file named neural_network.py. It's better to put the objective function you want to optimize in a file.\n",
    "<br> In this example, the worker.py file defines an evaluation function called instance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- The function takes the parameters for each instance from a field defined by the key 'hparameters'.\n",
    "- The function also returns 1 - loss because the NeuralNetwork is minimizing loss and the Optimizer is set to 'maximize' the function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275937cb-647b-4579-a4b2-bb6e8ba3568a",
   "metadata": {},
   "source": [
    "### Main \n",
    "- The network has 3 hidden layers and the ranges of each layer are as follows: [[32, 512], [32, 1024], [32, 512]],\n",
    "- Notice that there are 16 gpr processors (Bayesian Optimization step) and 4 GPU processers (training step)\n",
    "- Because the output layer is a vector of length 10 of ones and zeros we are using BCEWithLogitsLoss.\n",
    "- I am not using a softmax final function because for prediction, it seems to perform better without one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbeeae8-00d8-4b99-b08f-a1115505ec07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "gbatch_size = 200                      # number of elements in the gaussian optimzation batch\n",
    "g_procs = 4                            # cpus, number of batches for the gaussian optimization phase\n",
    "hp_ranges = [[32, 512], [32, 1024],    # the user defined function has to determine what to do with\n",
    "             [32, 512], [.0001, .01]]  # numbers randomly generated from this field\n",
    "n_procs = 2                            # number of gpus, need to be careful if using all 4, weird things can happen\n",
    "n_iter = 20                            # bayes optimization iterations\n",
    "logfile_name = 'logfile_2b.txt'\n",
    "\n",
    "\n",
    "oparameters = {'input_layer_size': 28*28, \n",
    "               'output_layer_size': 10, \n",
    "               'train_iterations': 10,   # neural network training iterations\n",
    "               'n_batches': 2,           # number of mini batches of batch_size for training\n",
    "               'batch_size': .01,        # size of mini batch, percent of total dataset\n",
    "               'train_test_files': {'x_train': 'nn_datasets/X_train.csv', # location of train, test files\n",
    "                                    'x_test': 'nn_datasets/X_train.csv',\n",
    "                                    'y_train': 'nn_datasets/y_train.csv', \n",
    "                                    'y_test': 'nn_datasets/y_test.csv'},\n",
    "               'device': 'cuda'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2bbf1-0dba-426e-b4bd-11cbda8c3c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    mnist_session = hp_tune.session(neural_network.instance,\n",
    "                                    hp_ranges=hp_ranges, \n",
    "                                    batch_sz=gbatch_size, n_gpr_processors=g_procs, \n",
    "                                    n_processors=n_procs, n_iter=n_iter, \n",
    "                                    other_parameters = oparameters, log_file=logfile_name, use_qc=False, bo_url='https://boaz.onrender.com')\n",
    "    p = mp.Pool()\n",
    "    start = time.time()\n",
    "    tuning_results  = mnist_session.tune(p)\n",
    "\n",
    "    print(\"{} total seconds\".format(round(time.time() - start,2)))\n",
    "    p.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3704a-a948-49f4-9474-5a3a3747eac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = mnist_session.summary()\n",
    "summary[summary['score']>.92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bf2f6-c54b-4dbb-a1e7-bd4ede479fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24226d9-07e8-4ec2-a27f-cadc3ce4c6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = summary[['score', 'iteration']].groupby('iteration').max().plot()\n",
    "best = [max(summary[summary['iteration']<=i]['score']) for i in range(n_iter+1)]\n",
    "p = plt.plot(best)\n",
    "plt.savefig('hptune4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e659c7f-4111-4882-bde2-55b5edb021a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = summary[['score', 'iteration']].groupby('iteration').max().plot()\n",
    "best = [max(summary[summary['iteration']<=i]['score']) for i in range(n_iter+1)]\n",
    "p = plt.plot(best)\n",
    "plt.savefig('hptune_11152024.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9941e-caf5-4fd3-af80-ea545d5decbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = summary[['score', 'iteration']].groupby('iteration').max().plot()\n",
    "best = [max(summary[summary['iteration']<=i]['score']) for i in range(n_iter+1)]\n",
    "p = plt.plot(best)\n",
    "plt.savefig('hptune.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edcb92e-0a1c-44e9-8498-17b42ab8bb95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "run = neptune.init_run(\n",
    "    project=\"mshipman/HPTune\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzNzhiNTgwMC05MDAzLTQ4NTQtOTk1NC04YWFlN2JkMDg4NWEifQ==\",\n",
    ")\n",
    "\n",
    "summary.to_csv(\"summary.csv\", index=False)\n",
    "run[\"summary/score_history.csv\"].upload(\"summary.csv\")\n",
    "\n",
    "params = {\"limits\": '('+') ('.join([\"{},{}\".format(x[0], x[1]) for x in hp_ranges])+')', \n",
    "          \"gpr_batch_size\": gbatch_size,\n",
    "          \"n_gpr_processors\": g_procs, \"n_processors\": n_procs,\n",
    "          \"n_iterations\": n_iter, \"other_parameters\": oparameters}\n",
    "run[\"parameters\"] = params\n",
    "run[\"summary/best_by_iteration.png\"].upload(\"hptune.png\")\n",
    "run['historical/best'] = ','.join([str(x) for x in best])\n",
    "run[\"log\"].upload(logfile_name)\n",
    "run.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86829562-37da-4ff7-82d0-b4f04c6270aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
