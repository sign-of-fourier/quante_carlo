{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4daf6cc8-4974-4af7-999d-e5ec703536e3",
   "metadata": {},
   "source": [
    "# Tutorial for batch hyper parameter tuing using Quante Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed38788-45a9-4d6d-939b-afd05bffdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from quante_carlo import hp_tune, worker\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from sklearn.datasets import load_diabetes\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b21d6-fc4d-42a0-95b1-1a98aa5af444",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8b1b1-95a5-437c-9c71-0de9dffa0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_ranges = [[.01, .99], [.01, .99]]\n",
    "hp_types = ['float', 'float']\n",
    "gbatch_size = 100 # how many points to evaluate in bayesian optimization\n",
    "g_procs = 2 # how many requests to bayesian optimizer\n",
    "n_procs = 4 # how many processors am i running, bayesian optimizer will give you this many 'next points'\n",
    "n_iter = 50\n",
    "oparameters = {'model': 'ElasticNet',\n",
    "               'data': data}\n",
    "logfile_name = 'log.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15449f42-f41a-46f2-b9ba-f9aa243874e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    enet_tuner = hp_tune.session(worker.regression_worker,\n",
    "                                 hp_ranges=hp_ranges, \n",
    "                                 batch_sz=gbatch_size, n_gpr_processors=g_procs, use_qc='True',\n",
    "                                 n_processors=n_procs, n_iter=n_iter, \n",
    "#                                 bo_url='http://localhost:8000', # if you're running the optimizer locally\n",
    "                                 bo_url='https://boaz.onrender.com',\n",
    "                                 other_parameters = oparameters, log_file=logfile_name)\n",
    "\n",
    "    p = mp.Pool()\n",
    "    start = time.time()    \n",
    "    session = enet_tuner.tune(p)\n",
    "\n",
    "    print(\"{} seconds\".format(round(time.time() - start,2)))\n",
    "    p.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0b1a7-aba4-477a-bbea-46a0bd58f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(enet_tuner.summary()[['iteration', 'score']].groupby('iteration').max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92dae7-151c-4d52-a795-0851ccd5eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_tuner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39507d-9fee-4e3d-955f-67e0cf528708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rapids-venv]",
   "language": "python",
   "name": "conda-env-rapids-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
